"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.databases = void 0;
exports.databases = [
    {
        id: "pinecone",
        name: "Pinecone",
        logoId: "pinecone",
        description: "A vector database for building high-performance vector search applications",
        company: {
            name: "Pinecone Systems",
            founded: 2019,
            funding: "$138M",
            employees: 100,
        },
        features: {
            cloudNative: true,
            serverless: true,
            hybridSearch: true,
            metadataFiltering: true,
            batchOperations: true,
        },
        performance: {
            latency: "10ms",
            throughput: "100k qps",
            scalability: "auto",
            queryLatencyMs: 10,
            indexingSpeedVectorsPerSec: 100000,
            memoryUsageMb: 200,
            scalabilityScore: 90,
            accuracyScore: 85
        },
        security: {
            encryption: true,
            authentication: true,
            access_control: true,
            audit_logging: true,
        },
        algorithms: {
            hnsw: true,
            ivf: true,
            lsh: false,
            quantization: true,
        },
        searchCapabilities: {
            similaritySearch: true,
            hybridSearch: true,
            filtering: true,
            pagination: true,
        },
        aiCapabilities: {
            features: {
                embeddingGeneration: true,
                llmIntegration: true,
                ragSupport: true,
                semanticCaching: true,
                modelHosting: false,
                fineTuning: false,
            },
            scores: {
                llmIntegration: 9,
                embeddingGeneration: 8,
                ragSupport: 9,
                fineTuning: 3,
                modelHosting: 2,
            },
            supportedModels: {
                openai: true,
                huggingface: true,
                pytorch: true,
                tensorflow: true,
                langchain: true,
                llamaindex: true,
            },
            ragFeatures: [
                "Semantic search",
                "Metadata filtering",
                "Hybrid search",
                "Real-time updates",
                "Batch operations",
            ],
            ragLimitations: [
                "No built-in fine-tuning",
                "Limited model hosting",
                "No built-in caching",
            ],
        },
    },
    {
        id: "weaviate",
        name: "Weaviate",
        logoId: "weaviate",
        description: "An open-source vector database that allows you to store data objects and vector embeddings",
        company: {
            name: "SeMI Technologies",
            founded: 2019,
            funding: "$50M",
            employees: 50,
        },
        features: {
            cloudNative: true,
            serverless: false,
            hybridSearch: true,
            metadataFiltering: true,
            batchOperations: true,
        },
        performance: {
            latency: "15ms",
            throughput: "50k qps",
            scalability: "manual",
            queryLatencyMs: 15,
            indexingSpeedVectorsPerSec: 50000,
            memoryUsageMb: 250,
            scalabilityScore: 75,
            accuracyScore: 88
        },
        security: {
            encryption: true,
            authentication: true,
            access_control: true,
            audit_logging: true,
        },
        algorithms: {
            hnsw: true,
            ivf: true,
            lsh: true,
            quantization: true,
        },
        searchCapabilities: {
            similaritySearch: true,
            hybridSearch: true,
            filtering: true,
            pagination: true,
        },
        aiCapabilities: {
            features: {
                embeddingGeneration: true,
                llmIntegration: true,
                ragSupport: true,
                semanticCaching: true,
                modelHosting: true,
                fineTuning: true,
            },
            scores: {
                llmIntegration: 8,
                embeddingGeneration: 9,
                ragSupport: 8,
                fineTuning: 7,
                modelHosting: 8,
            },
            supportedModels: {
                openai: true,
                huggingface: true,
                pytorch: true,
                tensorflow: true,
                langchain: true,
                llamaindex: true,
            },
            ragFeatures: [
                "Semantic search",
                "Metadata filtering",
                "Hybrid search",
                "Real-time updates",
                "Batch operations",
                "Model hosting",
                "Fine-tuning support",
            ],
            ragLimitations: [
                "Complex setup",
                "Limited cloud options",
                "Steeper learning curve",
            ],
        },
    },
    {
        id: "milvus",
        name: "Milvus",
        logoId: "milvus",
        description: "An open-source vector database for scalable similarity search and AI applications",
        company: {
            name: "Zilliz",
            founded: 2019,
            funding: "$43M",
            employees: 100,
        },
        features: {
            cloudNative: true,
            serverless: false,
            hybridSearch: true,
            metadataFiltering: true,
            batchOperations: true,
        },
        performance: {
            latency: "5ms",
            throughput: "200k qps",
            scalability: "manual",
            queryLatencyMs: 5,
            indexingSpeedVectorsPerSec: 200000,
            memoryUsageMb: 300,
            scalabilityScore: 80,
            accuracyScore: 90
        },
        security: {
            encryption: true,
            authentication: true,
            access_control: true,
            audit_logging: true,
        },
        algorithms: {
            hnsw: true,
            ivf: true,
            lsh: true,
            quantization: true,
        },
        searchCapabilities: {
            similaritySearch: true,
            hybridSearch: true,
            filtering: true,
            pagination: true,
        },
        aiCapabilities: {
            features: {
                embeddingGeneration: false,
                llmIntegration: true,
                ragSupport: true,
                semanticCaching: true,
                modelHosting: true,
                fineTuning: true,
            },
            scores: {
                llmIntegration: 7,
                embeddingGeneration: 4,
                ragSupport: 7,
                fineTuning: 6,
                modelHosting: 7,
            },
            supportedModels: {
                openai: true,
                huggingface: true,
                pytorch: true,
                tensorflow: true,
                langchain: true,
                llamaindex: true,
            },
            ragFeatures: [
                "Semantic search",
                "Metadata filtering",
                "Hybrid search",
                "Real-time updates",
                "Batch operations",
                "Model hosting",
                "Fine-tuning support",
            ],
            ragLimitations: [
                "No built-in embedding generation",
                "Complex deployment",
                "Limited documentation",
            ],
        },
    },
    {
        id: "deep lake",
        name: "Deep Lake",
        logoId: "deeplake",
        description: "Deep Lake is an AI database that provides storage, querying, and vector search capabilities for deep-learning and LLM-based applications.",
        company: {
            name: "Activeloop Inc.",
            founded: 2019,
            funding: "$8.8M",
            employees: 11,
        },
        features: {
            cloudNative: true,
            serverless: false,
            hybridSearch: true,
            metadataFiltering: true,
            batchOperations: true,
        },
        performance: {
            latency: "25ms",
            throughput: "10k qps",
            scalability: "auto",
            queryLatencyMs: 25,
            indexingSpeedVectorsPerSec: 10000,
            memoryUsageMb: 500,
            scalabilityScore: 85,
            accuracyScore: 80
        },
        security: {
            encryption: true,
            authentication: true,
            access_control: true,
            audit_logging: false,
        },
        algorithms: {
            hnsw: true,
            ivf: false,
            lsh: false,
            quantization: false,
        },
        searchCapabilities: {
            similaritySearch: true,
            hybridSearch: true,
            filtering: true,
            pagination: true,
        },
        aiCapabilities: {
            features: {
                embeddingGeneration: false,
                llmIntegration: true,
                ragSupport: true,
                semanticCaching: false,
                modelHosting: false,
                fineTuning: false,
            },
            scores: {
                llmIntegration: 7,
                embeddingGeneration: 5,
                ragSupport: 7,
                fineTuning: 3,
                modelHosting: 3,
            },
            supportedModels: {
                openai: true,
                huggingface: true,
                pytorch: false,
                tensorflow: false,
                langchain: true,
                llamaindex: true,
            },
            ragFeatures: ["Semantic search", "Metadata filtering", "Hybrid search", "Real-time updates", "Batch operations"],
            ragLimitations: ["No built-in fine-tuning", "Limited model hosting", "No built-in caching"],
        },
    },
    {
        id: "vespa",
        name: "Vespa",
        logoId: "vespa",
        description: "Vespa is a versatile search and serving engine that combines vector search with traditional search and ranking capabilities.",
        company: {
            name: "Yahoo",
            founded: 2017,
            funding: "N/A (Part of Yahoo)",
            employees: 100,
        },
        features: {
            cloudNative: true,
            serverless: false,
            hybridSearch: true,
            metadataFiltering: true,
            batchOperations: true,
        },
        performance: {
            latency: "25ms",
            throughput: "10k qps",
            scalability: "auto",
            queryLatencyMs: 25,
            indexingSpeedVectorsPerSec: 10000,
            memoryUsageMb: 500,
            scalabilityScore: 85,
            accuracyScore: 80
        },
        security: {
            encryption: true,
            authentication: true,
            access_control: true,
            audit_logging: false,
        },
        algorithms: {
            hnsw: true,
            ivf: false,
            lsh: false,
            quantization: false,
        },
        searchCapabilities: {
            similaritySearch: true,
            hybridSearch: true,
            filtering: true,
            pagination: true,
        },
        aiCapabilities: {
            features: {
                embeddingGeneration: false,
                llmIntegration: true,
                ragSupport: true,
                semanticCaching: false,
                modelHosting: false,
                fineTuning: false,
            },
            scores: {
                llmIntegration: 7,
                embeddingGeneration: 5,
                ragSupport: 7,
                fineTuning: 3,
                modelHosting: 3,
            },
            supportedModels: {
                openai: true,
                huggingface: true,
                pytorch: false,
                tensorflow: false,
                langchain: true,
                llamaindex: false,
            },
            ragFeatures: ["Semantic search", "Metadata filtering", "Hybrid search", "Real-time updates", "Batch operations"],
            ragLimitations: ["No built-in fine-tuning", "Limited model hosting", "No built-in caching"],
        },
    },
    {
        id: "faiss",
        name: "FAISS",
        logoId: "faiss",
        description: "FAISS (Facebook AI Similarity Search) is a library for efficient similarity search and clustering of dense vectors.",
        company: {
            name: "Meta (Facebook) AI Research",
            founded: 2017,
            funding: "N/A (Part of Meta)",
            employees: 0,
        },
        features: {
            cloudNative: false,
            serverless: false,
            hybridSearch: false,
            metadataFiltering: false,
            batchOperations: true,
        },
        performance: {
            latency: "25ms",
            throughput: "10k qps",
            scalability: "manual",
            queryLatencyMs: 25,
            indexingSpeedVectorsPerSec: 10000,
            memoryUsageMb: 500,
            scalabilityScore: 70,
            accuracyScore: 80
        },
        security: {
            encryption: false,
            authentication: false,
            access_control: false,
            audit_logging: false,
        },
        algorithms: {
            hnsw: true,
            ivf: true,
            lsh: false,
            quantization: true,
        },
        searchCapabilities: {
            similaritySearch: true,
            hybridSearch: false,
            filtering: false,
            pagination: true,
        },
        aiCapabilities: {
            features: {
                embeddingGeneration: false,
                llmIntegration: false,
                ragSupport: false,
                semanticCaching: false,
                modelHosting: false,
                fineTuning: false,
            },
            scores: {
                llmIntegration: 3,
                embeddingGeneration: 5,
                ragSupport: 3,
                fineTuning: 3,
                modelHosting: 3,
            },
            supportedModels: {
                openai: false,
                huggingface: false,
                pytorch: false,
                tensorflow: false,
                langchain: false,
                llamaindex: false,
            },
            ragFeatures: ["Semantic search", "Real-time updates", "Batch operations"],
            ragLimitations: ["No built-in fine-tuning", "Limited model hosting", "No built-in caching"],
        },
    },
    {
        id: "qdrant",
        name: "Qdrant",
        logoId: "qdrant",
        description: "Qdrant is a vector similarity search engine and database with extended filtering support.",
        company: {
            name: "Qdrant",
            founded: 2021,
            funding: "$2M",
            employees: 11,
        },
        features: {
            cloudNative: true,
            serverless: false,
            hybridSearch: true,
            metadataFiltering: true,
            batchOperations: true,
        },
        performance: {
            latency: "25ms",
            throughput: "10k qps",
            scalability: "auto",
            queryLatencyMs: 25,
            indexingSpeedVectorsPerSec: 10000,
            memoryUsageMb: 500,
            scalabilityScore: 85,
            accuracyScore: 80
        },
        security: {
            encryption: true,
            authentication: true,
            access_control: true,
            audit_logging: false,
        },
        algorithms: {
            hnsw: true,
            ivf: false,
            lsh: false,
            quantization: false,
        },
        searchCapabilities: {
            similaritySearch: true,
            hybridSearch: true,
            filtering: true,
            pagination: true,
        },
        aiCapabilities: {
            features: {
                embeddingGeneration: false,
                llmIntegration: true,
                ragSupport: true,
                semanticCaching: false,
                modelHosting: false,
                fineTuning: false,
            },
            scores: {
                llmIntegration: 7,
                embeddingGeneration: 5,
                ragSupport: 7,
                fineTuning: 3,
                modelHosting: 3,
            },
            supportedModels: {
                openai: true,
                huggingface: true,
                pytorch: false,
                tensorflow: false,
                langchain: true,
                llamaindex: true,
            },
            ragFeatures: ["Semantic search", "Metadata filtering", "Hybrid search", "Real-time updates", "Batch operations"],
            ragLimitations: ["No built-in fine-tuning", "Limited model hosting", "No built-in caching"],
        },
    },
    {
        id: "chroma",
        name: "Chroma",
        logoId: "chroma",
        description: "Chroma is an open-source embedding database for building AI applications with language models and embeddings.",
        company: {
            name: "Chroma",
            founded: 2022,
            funding: "$18M",
            employees: 11,
        },
        features: {
            cloudNative: true,
            serverless: false,
            hybridSearch: true,
            metadataFiltering: true,
            batchOperations: true,
        },
        performance: {
            latency: "25ms",
            throughput: "10k qps",
            scalability: "auto",
            queryLatencyMs: 25,
            indexingSpeedVectorsPerSec: 10000,
            memoryUsageMb: 500,
            scalabilityScore: 85,
            accuracyScore: 80
        },
        security: {
            encryption: true,
            authentication: true,
            access_control: true,
            audit_logging: false,
        },
        algorithms: {
            hnsw: true,
            ivf: false,
            lsh: false,
            quantization: false,
        },
        searchCapabilities: {
            similaritySearch: true,
            hybridSearch: true,
            filtering: true,
            pagination: true,
        },
        aiCapabilities: {
            features: {
                embeddingGeneration: false,
                llmIntegration: true,
                ragSupport: true,
                semanticCaching: false,
                modelHosting: false,
                fineTuning: false,
            },
            scores: {
                llmIntegration: 7,
                embeddingGeneration: 5,
                ragSupport: 7,
                fineTuning: 3,
                modelHosting: 3,
            },
            supportedModels: {
                openai: true,
                huggingface: true,
                pytorch: false,
                tensorflow: false,
                langchain: true,
                llamaindex: true,
            },
            ragFeatures: ["Semantic search", "Metadata filtering", "Hybrid search", "Real-time updates", "Batch operations"],
            ragLimitations: ["No built-in fine-tuning", "Limited model hosting", "No built-in caching"],
        },
    },
    {
        id: "elasticsearch",
        name: "Elasticsearch",
        logoId: "elasticsearch",
        description: "Elasticsearch is a distributed, RESTful search and analytics engine capable of addressing a growing number of use cases, including vector search.",
        company: {
            name: "Elastic N.V.",
            founded: 2012,
            funding: "$104M",
            employees: 2000,
        },
        features: {
            cloudNative: true,
            serverless: false,
            hybridSearch: true,
            metadataFiltering: true,
            batchOperations: true,
        },
        performance: {
            latency: "25ms",
            throughput: "10k qps",
            scalability: "auto",
            queryLatencyMs: 25,
            indexingSpeedVectorsPerSec: 10000,
            memoryUsageMb: 500,
            scalabilityScore: 85,
            accuracyScore: 80
        },
        security: {
            encryption: true,
            authentication: true,
            access_control: true,
            audit_logging: false,
        },
        algorithms: {
            hnsw: true,
            ivf: false,
            lsh: false,
            quantization: false,
        },
        searchCapabilities: {
            similaritySearch: true,
            hybridSearch: true,
            filtering: true,
            pagination: true,
        },
        aiCapabilities: {
            features: {
                embeddingGeneration: false,
                llmIntegration: true,
                ragSupport: true,
                semanticCaching: false,
                modelHosting: false,
                fineTuning: false,
            },
            scores: {
                llmIntegration: 7,
                embeddingGeneration: 5,
                ragSupport: 7,
                fineTuning: 3,
                modelHosting: 3,
            },
            supportedModels: {
                openai: true,
                huggingface: true,
                pytorch: false,
                tensorflow: false,
                langchain: true,
                llamaindex: false,
            },
            ragFeatures: ["Semantic search", "Metadata filtering", "Hybrid search", "Real-time updates", "Batch operations"],
            ragLimitations: ["No built-in fine-tuning", "Limited model hosting", "No built-in caching"],
        },
    },
    {
        id: "pgvector",
        name: "pgvector",
        logoId: "pgvector",
        description: "pgvector is an open-source extension for PostgreSQL that adds support for vector similarity search, enabling AI applications and embeddings directly within PostgreSQL.",
        company: {
            name: "PostgreSQL Global Development Group",
            founded: 2021,
            funding: "N/A (Open Source Project)",
            employees: 0,
        },
        features: {
            cloudNative: true,
            serverless: false,
            hybridSearch: true,
            metadataFiltering: true,
            batchOperations: true,
        },
        performance: {
            latency: "25ms",
            throughput: "10k qps",
            scalability: "auto",
            queryLatencyMs: 25,
            indexingSpeedVectorsPerSec: 10000,
            memoryUsageMb: 500,
            scalabilityScore: 70,
            accuracyScore: 80
        },
        security: {
            encryption: true,
            authentication: true,
            access_control: true,
            audit_logging: false,
        },
        algorithms: {
            hnsw: false,
            ivf: false,
            lsh: false,
            quantization: false,
        },
        searchCapabilities: {
            similaritySearch: true,
            hybridSearch: true,
            filtering: true,
            pagination: true,
        },
        aiCapabilities: {
            features: {
                embeddingGeneration: false,
                llmIntegration: true,
                ragSupport: true,
                semanticCaching: false,
                modelHosting: false,
                fineTuning: false,
            },
            scores: {
                llmIntegration: 7,
                embeddingGeneration: 5,
                ragSupport: 7,
                fineTuning: 3,
                modelHosting: 3,
            },
            supportedModels: {
                openai: true,
                huggingface: true,
                pytorch: false,
                tensorflow: false,
                langchain: true,
                llamaindex: true,
            },
            ragFeatures: ["Semantic search", "Metadata filtering", "Hybrid search", "Real-time updates", "Batch operations"],
            ragLimitations: ["No built-in fine-tuning", "Limited model hosting", "No built-in caching"],
        },
    },
    {
        id: "redis",
        name: "Redis",
        logoId: "redis",
        description: "Redis is an open-source, in-memory data structure store that can be used as a database, cache, and message broker. With the RediSearch module, it offers vector similarity search capabilities.",
        company: {
            name: "Redis Ltd.",
            founded: 2011,
            funding: "$347M",
            employees: 500,
        },
        features: {
            cloudNative: true,
            serverless: false,
            hybridSearch: true,
            metadataFiltering: true,
            batchOperations: true,
        },
        performance: {
            latency: "25ms",
            throughput: "10k qps",
            scalability: "auto",
            queryLatencyMs: 25,
            indexingSpeedVectorsPerSec: 10000,
            memoryUsageMb: 500,
            scalabilityScore: 85,
            accuracyScore: 80
        },
        security: {
            encryption: true,
            authentication: true,
            access_control: true,
            audit_logging: false,
        },
        algorithms: {
            hnsw: true,
            ivf: false,
            lsh: false,
            quantization: false,
        },
        searchCapabilities: {
            similaritySearch: true,
            hybridSearch: true,
            filtering: true,
            pagination: true,
        },
        aiCapabilities: {
            features: {
                embeddingGeneration: false,
                llmIntegration: true,
                ragSupport: true,
                semanticCaching: false,
                modelHosting: false,
                fineTuning: false,
            },
            scores: {
                llmIntegration: 7,
                embeddingGeneration: 5,
                ragSupport: 7,
                fineTuning: 3,
                modelHosting: 3,
            },
            supportedModels: {
                openai: true,
                huggingface: true,
                pytorch: false,
                tensorflow: false,
                langchain: true,
                llamaindex: false,
            },
            ragFeatures: ["Semantic search", "Metadata filtering", "Hybrid search", "Real-time updates", "Batch operations"],
            ragLimitations: ["No built-in fine-tuning", "Limited model hosting", "No built-in caching"],
        },
    },
    {
        id: "lancedb",
        name: "LanceDB",
        logoId: "lancedb",
        description: "LanceDB is an open-source database built for AI applications with vector search capabilities and a focus on simplicity and performance.",
        company: {
            name: "LanceDB",
            founded: 2023,
            funding: "Seed",
            employees: 1,
        },
        features: {
            cloudNative: true,
            serverless: false,
            hybridSearch: true,
            metadataFiltering: true,
            batchOperations: true,
        },
        performance: {
            latency: "25ms",
            throughput: "10k qps",
            scalability: "auto",
            queryLatencyMs: 25,
            indexingSpeedVectorsPerSec: 10000,
            memoryUsageMb: 500,
            scalabilityScore: 85,
            accuracyScore: 80
        },
        security: {
            encryption: true,
            authentication: true,
            access_control: true,
            audit_logging: false,
        },
        algorithms: {
            hnsw: true,
            ivf: false,
            lsh: false,
            quantization: false,
        },
        searchCapabilities: {
            similaritySearch: true,
            hybridSearch: true,
            filtering: true,
            pagination: true,
        },
        aiCapabilities: {
            features: {
                embeddingGeneration: false,
                llmIntegration: true,
                ragSupport: true,
                semanticCaching: false,
                modelHosting: false,
                fineTuning: false,
            },
            scores: {
                llmIntegration: 7,
                embeddingGeneration: 5,
                ragSupport: 7,
                fineTuning: 3,
                modelHosting: 3,
            },
            supportedModels: {
                openai: true,
                huggingface: true,
                pytorch: false,
                tensorflow: false,
                langchain: true,
                llamaindex: true,
            },
            ragFeatures: ["Semantic search", "Metadata filtering", "Hybrid search", "Real-time updates", "Batch operations"],
            ragLimitations: ["No built-in fine-tuning", "Limited model hosting", "No built-in caching"],
        },
    },
    {
        id: "marqo",
        name: "Marqo",
        logoId: "marqo",
        description: "Marqo is a tensor search engine that makes it easy to build AI-powered search into applications.",
        company: {
            name: "Marqo",
            founded: 2022,
            funding: "Seed",
            employees: 11,
        },
        features: {
            cloudNative: true,
            serverless: false,
            hybridSearch: true,
            metadataFiltering: true,
            batchOperations: true,
        },
        performance: {
            latency: "25ms",
            throughput: "10k qps",
            scalability: "auto",
            queryLatencyMs: 25,
            indexingSpeedVectorsPerSec: 10000,
            memoryUsageMb: 500,
            scalabilityScore: 85,
            accuracyScore: 80
        },
        security: {
            encryption: true,
            authentication: true,
            access_control: true,
            audit_logging: false,
        },
        algorithms: {
            hnsw: true,
            ivf: false,
            lsh: false,
            quantization: false,
        },
        searchCapabilities: {
            similaritySearch: true,
            hybridSearch: true,
            filtering: true,
            pagination: true,
        },
        aiCapabilities: {
            features: {
                embeddingGeneration: false,
                llmIntegration: true,
                ragSupport: true,
                semanticCaching: false,
                modelHosting: false,
                fineTuning: false,
            },
            scores: {
                llmIntegration: 7,
                embeddingGeneration: 5,
                ragSupport: 7,
                fineTuning: 3,
                modelHosting: 3,
            },
            supportedModels: {
                openai: true,
                huggingface: true,
                pytorch: false,
                tensorflow: false,
                langchain: true,
                llamaindex: false,
            },
            ragFeatures: ["Semantic search", "Metadata filtering", "Hybrid search", "Real-time updates", "Batch operations"],
            ragLimitations: ["No built-in fine-tuning", "Limited model hosting", "No built-in caching"],
        },
    },
    {
        id: "singlestoredb",
        name: "SingleStoreDB",
        logoId: "singlestore",
        description: "SingleStoreDB is a distributed SQL database that combines transactional and analytical processing with vector search capabilities.",
        company: {
            name: "SingleStore",
            founded: 2011,
            funding: "$318.1M",
            employees: 251,
        },
        features: {
            cloudNative: true,
            serverless: false,
            hybridSearch: true,
            metadataFiltering: true,
            batchOperations: true,
        },
        performance: {
            latency: "25ms",
            throughput: "10k qps",
            scalability: "auto",
            queryLatencyMs: 25,
            indexingSpeedVectorsPerSec: 10000,
            memoryUsageMb: 500,
            scalabilityScore: 85,
            accuracyScore: 80
        },
        security: {
            encryption: true,
            authentication: true,
            access_control: true,
            audit_logging: false,
        },
        algorithms: {
            hnsw: false,
            ivf: true,
            lsh: false,
            quantization: false,
        },
        searchCapabilities: {
            similaritySearch: true,
            hybridSearch: true,
            filtering: true,
            pagination: true,
        },
        aiCapabilities: {
            features: {
                embeddingGeneration: false,
                llmIntegration: true,
                ragSupport: true,
                semanticCaching: false,
                modelHosting: false,
                fineTuning: false,
            },
            scores: {
                llmIntegration: 7,
                embeddingGeneration: 5,
                ragSupport: 7,
                fineTuning: 3,
                modelHosting: 3,
            },
            supportedModels: {
                openai: true,
                huggingface: true,
                pytorch: false,
                tensorflow: false,
                langchain: true,
                llamaindex: false,
            },
            ragFeatures: ["Semantic search", "Metadata filtering", "Hybrid search", "Real-time updates", "Batch operations"],
            ragLimitations: ["No built-in fine-tuning", "Limited model hosting", "No built-in caching"],
        },
    },
    {
        id: "vald",
        name: "Vald",
        logoId: "vald",
        description: "Vald is a highly scalable distributed vector search engine designed for speed and scalability.",
        company: {
            name: "Yahoo Japan Corporation",
            founded: 2019,
            funding: "N/A (Part of Yahoo Japan)",
            employees: 0,
        },
        features: {
            cloudNative: true,
            serverless: false,
            hybridSearch: true,
            metadataFiltering: true,
            batchOperations: true,
        },
        performance: {
            latency: "25ms",
            throughput: "10k qps",
            scalability: "auto",
            queryLatencyMs: 25,
            indexingSpeedVectorsPerSec: 10000,
            memoryUsageMb: 500,
            scalabilityScore: 85,
            accuracyScore: 80
        },
        security: {
            encryption: true,
            authentication: true,
            access_control: true,
            audit_logging: false,
        },
        algorithms: {
            hnsw: true,
            ivf: false,
            lsh: false,
            quantization: false,
        },
        searchCapabilities: {
            similaritySearch: true,
            hybridSearch: true,
            filtering: true,
            pagination: true,
        },
        aiCapabilities: {
            features: {
                embeddingGeneration: false,
                llmIntegration: false,
                ragSupport: false,
                semanticCaching: false,
                modelHosting: false,
                fineTuning: false,
            },
            scores: {
                llmIntegration: 3,
                embeddingGeneration: 5,
                ragSupport: 3,
                fineTuning: 3,
                modelHosting: 3,
            },
            supportedModels: {
                openai: false,
                huggingface: false,
                pytorch: false,
                tensorflow: false,
                langchain: false,
                llamaindex: false,
            },
            ragFeatures: ["Semantic search", "Metadata filtering", "Hybrid search", "Real-time updates", "Batch operations"],
            ragLimitations: ["No built-in fine-tuning", "Limited model hosting", "No built-in caching"],
        },
    },
    {
        id: "docarray",
        name: "DocArray",
        logoId: "docarray",
        description: "DocArray is a library for nested, unstructured data in transit, including vector data and neural search capabilities.",
        company: {
            name: "Jina AI",
            founded: 2020,
            funding: "$37.5M",
            employees: 51,
        },
        features: {
            cloudNative: true,
            serverless: false,
            hybridSearch: true,
            metadataFiltering: true,
            batchOperations: true,
        },
        performance: {
            latency: "25ms",
            throughput: "10k qps",
            scalability: "auto",
            queryLatencyMs: 25,
            indexingSpeedVectorsPerSec: 10000,
            memoryUsageMb: 500,
            scalabilityScore: 85,
            accuracyScore: 80
        },
        security: {
            encryption: true,
            authentication: true,
            access_control: true,
            audit_logging: false,
        },
        algorithms: {
            hnsw: true,
            ivf: false,
            lsh: false,
            quantization: false,
        },
        searchCapabilities: {
            similaritySearch: true,
            hybridSearch: true,
            filtering: true,
            pagination: true,
        },
        aiCapabilities: {
            features: {
                embeddingGeneration: false,
                llmIntegration: false,
                ragSupport: false,
                semanticCaching: false,
                modelHosting: false,
                fineTuning: false,
            },
            scores: {
                llmIntegration: 3,
                embeddingGeneration: 5,
                ragSupport: 3,
                fineTuning: 3,
                modelHosting: 3,
            },
            supportedModels: {
                openai: false,
                huggingface: false,
                pytorch: false,
                tensorflow: false,
                langchain: false,
                llamaindex: false,
            },
            ragFeatures: ["Semantic search", "Metadata filtering", "Hybrid search", "Real-time updates", "Batch operations"],
            ragLimitations: ["No built-in fine-tuning", "Limited model hosting", "No built-in caching"],
        },
    },
];
