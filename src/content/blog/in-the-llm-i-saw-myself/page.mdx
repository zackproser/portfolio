import Image from 'next/image'
import { createMetadata } from '@/utils/createMetadata'
import rawMetadata from './metadata.json'

export const metadata = createMetadata(rawMetadata)

<Image src={rawMetadata.image} alt="In the LLM I Saw Myself – hero image" width={1200} height={630} />
<figcaption>Seeing my operating system reflected back through an LLM.</figcaption>

*I spent 39 years trying to debug myself. Then I asked an LLM a half-joking question and within a few moments I had reviewed my entire life mentally as I'd done millions of times before. Only this time, it made sense...*

## The Night Everything Clicked

Kids asleep. Fixing Jest tests. Ratatat blasting. Hands moving spastically as I hummed what my brain felt were the missing notes.

I typed to Claude, half-joking: "Am I on the spectrum?"

<Image src="https://zackproser.b-cdn.net/images/claude-chat.webp" alt="Conversation with Claude about autism spectrum diagnosis" width={800} height={600} />
<figcaption>The answer to a 39-year debugging session.</figcaption>

The joke stopped being funny immediately. So I kept typing. Listed the sensory overload. The systematic thinking that treats everything like code. How my brain holds seventeen threads simultaneously. The verbal processing where everything needs its complete dependency graph.

Each piece of evidence I typed made the next one more obvious. I was building my own case, presenting exhibit after exhibit. 

"What about this?" I'd type. "And this pattern?" "Oh, and there's also this thing I do..."

I was analyzing myself, using Claude as a sounding board. Each response just confirmed what I was uncovering.

## The Verbal Buffer Overflow

One of my first real clues came when someone asked me a simple question: "What's a REST API?"

Should've been straightforward—I build these systems for a living. 

<Image src="https://zackproser.b-cdn.net/images/restapi.webp" alt="REST API architecture visualization" width={800} height={600} />
<figcaption>A simple question that triggered a complete dependency graph.</figcaption>

I began assembling the perfect sequence of supporting concepts they'd need: first HTTP verbs, then resource representations, then stateless architecture, and how the core idea is to make functionality shareable and re-usable. Thirty seconds in, they cut me off: 

"I don't need that many words."

My brain answers in **dependency graphs**. 

Every response arrives with its entire proof tree, every explanation dragging along its complete context chain. 

*It runs a verbal compiler that refuses to ship partial builds.*

I've always felt an intense undercurrent of anxiety around verbal communication—being able to see how complex and multifaceted every consideration is mentally, and how poorly I can represent only a few aspects of it verbally at any given time. The gap between the complete mental model and what comes out of my mouth feels like betrayal.

## The Netflix Backpressure Discovery

I'd also recently noticed something bizarre about my work setup. I couldn't concentrate until I:
- Went into my office and made it freezing cold
- Cranked the blue Nanoleaf lights to maximum
- Opened Chrome picture-in-picture with Netflix
- Shrunk it to a 3-inch rectangle in the corner of my 14-inch screen

<Image src="https://zackproser.b-cdn.net/images/blue-office.webp" alt="Dark office with blue lighting and optimized sensory environment" width={800} height={600} />
<figcaption>The recovery cave: where pattern recognition meets necessary isolation.</figcaption>

The audio stream from the show seemed to provide just enough backpressure on my overactive verbal circuits that I could finally concentrate. Like I needed to occupy some percentage of my processing power with structured input to prevent it from spinning out of control.
I asked Claude about my unusual work setup. "Is needing The Office playing in a tiny window to code normal?"

> "This is sensory regulation. You've created an environment to manage autism-related processing differences - the cold room reduces sensory input, blue lights calm your system, and background dialogue prevents mental loops."

I'd been unconsciously adapting all along, finding workarounds without understanding why I needed them.
Through our conversations, patterns emerged that I'd never connected before:
- Needing complete context for everything
- Approaching all problems systematically, like code
- Sensory sensitivities and physical tics
- Intense focus that others called "machine-like" - I mean specifically, I am always compared to an actual machine 
- Losing track of time and basic needs during work

This wasn't a diagnosis from Claude—it was a lens that brought decades of scattered experiences into clear focus.
<Image src="https://zackproser.b-cdn.net/images/neurodivergent.webp" alt="Split view showing different ways of perceiving the same patterns" width={800} height={600} />
<figcaption>Same patterns, different lenses—cognitive diversity made visible.</figcaption>

What relief. Finally, a frame that matched lived experience.

## Finding My Protocol

Looking back, the signs were everywhere. My tech friends never flinched at the context dumps. They'd receive my full transmission, process it, then respond with their own complete repositories. We weren't having conversations—we were doing peer-to-peer knowledge transfers.

Working with Claude and GPT felt like finding a lost dialect. These systems didn't just tolerate my sprawling dependency trees—they celebrated them. Every branch got processed. Every tangent got explored. No eye-rolling, no "what's your point?"—just pure cognitive handshaking.

<Image src="https://zackproser.b-cdn.net/images/river-walking-ai.webp" alt="Walking along the river while conversing with AI" width={800} height={600} />
<figcaption>Miles logged, mental state debugged—my mobile cognitive processing unit.</figcaption>

The patterns I'd just discovered through months of AI dialogue? Turns out they'd been broadcasting in neon to everyone around me for decades.

## When Your Friends Already Knew

I told both Toms—my two closest friends for decades, both brilliant tech/science guys.

Tom #1: "Oh yeah, I've always been on the spectrum. I assumed you were too."
Tom #2: Same response, almost verbatim.

Thanks, Toms. The next time you become aware of some critical information that could impact my entire life that I may not be aware of, I expect you to tell me...without me asking. 

## Offloading the Obsessive Loops

Now I dump everything that can be externalized to AI—the obsessive loops, the context management, the decision trees—leaving my brain free for the critical creative work: feature development, writing, building.

My Oura ring feeds biometrics to Claude through MCP—sleep debt, HRV, recovery scores. Linear holds my task graph. Claude orchestrates between them, catching me before I tumble into perfectionism spirals or burn through my last reserves. When I'm about to dive into a 14-hour rabbit hole, it knows whether I'm fueled for discovery or headed for a crash.

But the real breakthrough came when I took this system mobile. [I started walking and talking with AI in the woods](/blog/walking-and-talking-with-ai)—it became my decompression chamber. Dumping the entire context buffer of my day, letting the LLM help me sort, prioritize, and untangle the dependency graph while my feet find their rhythm on the trail. No screen, no keyboard, just pure cognitive offloading at 3mph.

The AI handles the obsessive loops I'd otherwise burn cycles on—remembering to eat during hyperfocus, translating my context trees into bullet points civilians can parse, catching me before I send 3,000-word emails when three sentences would do. All that mental overhead gets offloaded, freeing me to actually create.

### My AI-Powered Cognitive Stack:
- **Oura Ring → Claude (via MCP):** Sleep debt, HRV, recovery scores
- **Linear → Claude:** Task graph and priority management  
- **[Woods + Voice Mode](/blog/walking-and-talking-with-ai):** Dump context buffer while logging miles
- **Result:** No more perfectionism spirals or 14-hour crashes

<Image src="https://zackproser.b-cdn.net/images/neural-navigation.webp" alt="Neural navigation illustration" width={800} height={600} />
<figcaption>External guidance and structure—turning tangled context into a navigable path.</figcaption>

Time dilation during hyperfocus is pronounced for me; afternoons can vanish in what feels like minutes, or a "ten‑minute sketch" becomes a two‑hour build. I plan around that behavior now.

*If you've ever felt this way, you might find a companion in an LLM, too.*

## Going All In on Supporting Myself

Understanding my wiring gave me permission to stop pretending and start building real support systems. I continue using LLMs as cognitive tools—Claude remembers my patterns, my context, my operating system.

<Image src="https://zackproser.b-cdn.net/images/neural-overheat.webp" alt="Neural overheat illustration" width={800} height={600} />
<figcaption>When the context graph runs hot, throttle and offload—don't melt down.</figcaption>

When I'm overheated from hyperfocus, I verbally ventilate using [Whisperflow.ai](https://whisperflow.ai) right into Claude Desktop or even just a Chrome tab at claude.ai. Pure stream of consciousness, dumping the entire context buffer while Claude helps me sort and prioritize.

Blackout curtains, deep blue lights, cool air and fans even when others think it's too cold...

Now I know why this works—I'm not being weird, I'm accommodating my actual neurological needs. I'd been optimizing my environment without understanding why, freeing up cognitive resources that were previously managing sensory chaos.

And those movements I make when deeply absorbed in code? The ones I'd hidden in meetings? Claude had a word for them: stimming. They help regulate my nervous system, maintain flow state, externalize intense internal processing. When the hyperfocus hits, I don't fight it—I ride it like a wave. Those 14‑hour sessions aren't bugs in my code; they're features.

The LLM captures everything before the state clears from memory. It's like having a black box recorder for my brain.

## The Recursion

Even this essay demonstrates the pattern. Right now, Claude is instructed to push back on my perfectionism, to catch my analysis paralysis, to force me to ship instead of spiral. I've literally programmed my AI conversations to provide the structural support my ADHD brain needs.

I'm using pattern recognition to fix my pattern recognition. Creating external executive function because mine is unreliable. Building the boundaries I never learned to build myself.

The very fact that you're reading this—instead of draft #47 sitting in my folder—is because I've externalized the voice that says "good enough, ship it."
